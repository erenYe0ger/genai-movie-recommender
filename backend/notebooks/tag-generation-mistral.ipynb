{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":14590480,"sourceType":"datasetVersion","datasetId":9319800}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers accelerate bitsandbytes sentencepiece","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:55:36.623123Z","iopub.execute_input":"2026-01-23T13:55:36.623451Z","iopub.status.idle":"2026-01-23T13:55:43.725850Z","shell.execute_reply.started":"2026-01-23T13:55:36.623423Z","shell.execute_reply":"2026-01-23T13:55:43.725079Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer\nimport torch\nimport json\nimport pickle\nimport os\n\nMODEL = \"mistralai/Mistral-7B-Instruct-v0.3\"\nDEVICE = \"cuda\"\n\ntokenizer = AutoTokenizer.from_pretrained(MODEL)\nmodel = AutoModelForCausalLM.from_pretrained(\n    MODEL,\n    torch_dtype=torch.float16,\n    device_map=\"auto\",\n    load_in_4bit=True\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:55:43.727417Z","iopub.execute_input":"2026-01-23T13:55:43.727729Z","iopub.status.idle":"2026-01-23T13:57:28.356435Z","shell.execute_reply.started":"2026-01-23T13:55:43.727667Z","shell.execute_reply":"2026-01-23T13:57:28.355518Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\ndf = pd.read_json(\"/kaggle/input/movies-dataset/movies.json\")  # change if needed\nmovies = df.to_dict(orient=\"records\")\nN = len(movies)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:57:28.357432Z","iopub.execute_input":"2026-01-23T13:57:28.358100Z","iopub.status.idle":"2026-01-23T13:57:28.520697Z","shell.execute_reply.started":"2026-01-23T13:57:28.358071Z","shell.execute_reply":"2026-01-23T13:57:28.520144Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.head(2)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:57:28.522207Z","iopub.execute_input":"2026-01-23T13:57:28.522441Z","iopub.status.idle":"2026-01-23T13:57:32.870034Z","shell.execute_reply.started":"2026-01-23T13:57:28.522419Z","shell.execute_reply":"2026-01-23T13:57:32.869353Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def join_list(x):\n    # Converts list of strings → single string\n    # example: [\"sci fi\", \"space\"] -> \"sci fi space\"\n    return \" \".join(x) if isinstance(x, list) else str(x)\n\n# Build text field for embeddings using ALL relevant columns except \"id\"\ndf[\"embedding_text\"] = (\n    df[\"title\"].fillna(\"\") + \" \" +\n    df[\"tagline\"].fillna(\"\") + \" \" +\n    df[\"overview\"].fillna(\"\") + \" \" +\n    df[\"genres\"].apply(join_list) + \" \" +\n    df[\"keywords\"].apply(join_list) + \" \" +\n    df[\"cast\"].apply(join_list) + \" \" +\n    df[\"crew\"].apply(join_list) + \" \" +\n    df[\"production_companies\"].apply(join_list)\n)\n\ndf[\"embedding_text\"].head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:57:32.870901Z","iopub.execute_input":"2026-01-23T13:57:32.871208Z","iopub.status.idle":"2026-01-23T13:57:32.904986Z","shell.execute_reply.started":"2026-01-23T13:57:32.871184Z","shell.execute_reply":"2026-01-23T13:57:32.904104Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df[\"embedding_text\"][0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:57:32.906174Z","iopub.execute_input":"2026-01-23T13:57:32.906457Z","iopub.status.idle":"2026-01-23T13:57:32.920076Z","shell.execute_reply.started":"2026-01-23T13:57:32.906432Z","shell.execute_reply":"2026-01-23T13:57:32.919454Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"BATCH_SIZE = 32\nSAVE_EVERY = 10  # batches\nOUT_DIR = \"/kaggle/working/tags/\"\nos.makedirs(OUT_DIR, exist_ok=True)\n\ndef make_prompt(text):\n    return (\n        'Generate 3–5 short style tags.\\n'\n        'Output ONLY a JSON list: [\"tag1\",\"tag2\",\"tag3\"]\\n\\n'\n        f'Movie: {text}'\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:57:32.920959Z","iopub.execute_input":"2026-01-23T13:57:32.921243Z","iopub.status.idle":"2026-01-23T13:57:32.933260Z","shell.execute_reply.started":"2026-01-23T13:57:32.921211Z","shell.execute_reply":"2026-01-23T13:57:32.932646Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# STEP 3 — Resume Support\n# ============================================\ndone_ranges = []\nfor f in os.listdir(OUT_DIR):\n    if f.endswith(\".pkl\"):\n        a, b = f.replace(\"tags_\", \"\").replace(\".pkl\",\"\").split(\"_\")\n        done_ranges.append((int(a), int(b)))\n\ndef is_done(idx):\n    for a, b in done_ranges:\n        if a <= idx <= b:\n            return True\n    return False","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:57:32.934093Z","iopub.execute_input":"2026-01-23T13:57:32.934359Z","iopub.status.idle":"2026-01-23T13:57:32.946650Z","shell.execute_reply.started":"2026-01-23T13:57:32.934337Z","shell.execute_reply":"2026-01-23T13:57:32.946173Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# ============================================\n# STEP 4 — Main Loop\n# ============================================\nbuffer = {}\nbatch_count = 0\nstart_index = 0\n\n# find resume point\nfor i in range(0, N, BATCH_SIZE):\n    idx = min(i + BATCH_SIZE - 1, N - 1)\n    if not is_done(i) and not is_done(idx):\n        start_index = i\n        break\n\nprint(\"Resuming from:\", start_index)\n\nfor i in range(start_index, N, BATCH_SIZE):\n    batch = df.iloc[i:i+BATCH_SIZE]\n\n    for _, m in batch.iterrows():\n        text = m[\"embedding_text\"]\n        prompt = make_prompt(text)\n\n        inputs = tokenizer(prompt, return_tensors=\"pt\").to(DEVICE)\n        with torch.no_grad():\n            out = model.generate(\n                **inputs,\n                max_new_tokens=64,\n                temperature=0.2,\n                top_p=0.9,\n                do_sample=True\n            )\n        resp = tokenizer.decode(out[0], skip_special_tokens=True)\n        buffer[m[\"id\"]] = resp\n\n\n    batch_count += 1\n\n    # save every 10 batches\n    if batch_count % SAVE_EVERY == 0:\n        a = i - (SAVE_EVERY - 1) * BATCH_SIZE\n        b = i + BATCH_SIZE - 1\n        b = min(b, N - 1)\n        name = f\"tags_{a:04d}_{b:04d}.pkl\"\n        with open(os.path.join(OUT_DIR, name), \"wb\") as f:\n            pickle.dump(buffer, f)\n        buffer = {}\n\n# save last leftover\nif buffer:\n    a = (N // (BATCH_SIZE * SAVE_EVERY)) * (BATCH_SIZE * SAVE_EVERY)\n    b = N - 1\n    name = f\"tags_{a:04d}_{b:04d}.pkl\"\n    with open(os.path.join(OUT_DIR, name), \"wb\") as f:\n        pickle.dump(buffer, f)\n\nprint(\"DONE.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-23T13:57:32.947500Z","iopub.execute_input":"2026-01-23T13:57:32.947785Z","iopub.status.idle":"2026-01-23T13:57:32.959531Z","shell.execute_reply.started":"2026-01-23T13:57:32.947764Z","shell.execute_reply":"2026-01-23T13:57:32.958847Z"}},"outputs":[],"execution_count":null}]}